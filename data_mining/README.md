## Data Science Summer School at Gachon University
본 코드는 2016년 가천대학교 산업경영공학과 TeamLab에서 운영한 데이터마이닝 여름학교에 활용한 자료들입니다. 강의 영상과 자료들은 순차적으로 업데이트 됩니다

## Course Info
* Course textbooks
    - [밑바닥부터 시작하는 데이터 과학](http://www.yes24.com/24/goods/27951467?scode=032&OzSrank=1) a.k.a. "scratch" (조엘 그루스, 2016)
    - [데이터 과학 입문](http://www.yes24.com/24/goods/14982043?scode=032&OzSrank=4) a.k.a. "DDS" (레이철 슈트 | 캐시 오닐, 2014)
* Course repository
    - [강의자료 on Docs.com](https://doc.co/miwc5C)
    - [강의영상 on Youtube](https://www.youtube.com/playlist?list=PLBHVuYlKEkUIbVgM5H_9fh7cE9u45fR1J)
    - [코드 on Github](https://github.com/TeamLab/data_school_at_gachon) - Here :)

## Course Prerequisites
* 입문 수준의 통계학
    - [세상에서 가장 쉬운 통계학](http://www.yes24.com/24/goods/3625262?scode=032&OzSrank=1) (고지마 히로유키, 2009) 
* 고교 이과 수준의 선형대수학 
    - [Linear Algebra] (https://www.khanacademy.org/math/linear-algebra) (Khan Academy)
    - [선형대수학](https://www.youtube.com/playlist?list=PLSN_PltQeOyjDGSghAf92VhdMBeaLZWR3) (한양대 이상화 교수, 2013) - Advance Course
* 리눅스 설치 (14.04+) 및 활용
    - [Linux - Ubuntu 14.04 설치하기] (http://studyforus.tistory.com/222)
    - [우분투-1604-설치과정-VMware-12-pro] (http://goodtogreate.tistory.com/entry/%EC%9A%B0%EB%B6%84%ED%88%AC-1604-%EC%84%A4%EC%B9%98%EA%B3%BC%EC%A0%95-VMware-12-pro)
    - [세상에서 가장 쉬운 리눅스](http://www.yes24.com/24/goods/12653103?scode=032&OzSrank=1) (웨일 소잉카, 2014)
    - [리눅스 활용 기초] (https://www.youtube.com/playlist?list=PL3zP7rnORnnBb0yZf4GMamxEuOusySpyk)
* 기초 파이썬 
    - Gachon CS50 - [Data structure: Dict type](https://www.youtube.com/playlist?list=PLBHVuYlKEkUJtTFNVy6c5OZ44878knlRS) (최성철, 2016)
    - Gachon CS50 -  [Pythonic code](https://www.youtube.com/watch?v=dFjuSonfEQI&list=PLBHVuYlKEkUJtTFNVy6c5OZ44878knlRS&index=8) (Gachon CS50 최성철, 2016)
    - Scratch - ch.2, ch.3, Ch.9, Ch.10
* Git
    - [Pro Git] (http://www.yes24.com/24/goods/24841824?scode=032&OzSrank=1) (스캇 샤콘 | 벤 스트라웁, 2016)
    - [Git 강의](https://www.youtube.com/playlist?list=PLuHgQVnccGMCB06JE7zFIAOJtdcZBVrap) (생활코딩, 2014)

## Course Contents

### Intro
* 데이터 과학 시작하기
    - 데이터 과학이란 무엇인가? - [강의자료](https://doc.co/t57U5G/miwc5C)
    - Machine Learning Overview - [강의자료](https://doc.co/ixxrYu/miwc5C)
    - How to Learn ML - [강의자료](https://doc.co/pu98fv/miwc5C)
    - Reading Materials 
        - Scratch - Ch.1 
        - DDS - Ch.1, Ch.2 
* Data science ecosystem for python
    - 파이썬 머신러닝 환경 개요
    - 파이썬 머신러닝 환경 설치 문서 
    - Miniconda installation - [강의영상](https://youtu.be/SAbunYOXaRU?list=PLBHVuYlKEkUIbVgM5H_9fh7cE9u45fR1J) 
    - Python Ecosystems for Machine Learning - [강의영상](https://youtu.be/BobZjJVZorY?list=PLBHVuYlKEkUIbVgM5H_9fh7cE9u45fR1J)
    - Pycharm installation - [강의영상](https://youtu.be/BobZjJVZorY)
* 파이썬으로 수식 다루기 
    - 선형대수
        - Scratch - Ch.4
    - 통계
        - Scratch - Ch.5, Ch.6, Ch.7
    - Numpy 
         - Gachon IME O.R. Honors - [Numpy](https://www.youtube.com/playlist?list=PLBHVuYlKEkULZLnKLzRq1CnNBOBlBTkqp) (최성철, 2016)
         - TF-KR 첫 모임: Zen of NumPy - [발표자료](https://speakerdeck.com/shurain/zen-of-numpy), [강의영상](https://www.youtube.com/watch?v=Dm2wkObQSas&index=2&list=PLlMkM4tgfjnIMPagE47noYAJ222zWc4rw) (하성주, 2016)

### 지도 학습 (Supervised learning)
* 선형 회귀 (Linear Regression)
    - Lecture: 상관분석 - [강의자료](https://doc.co/ALbkA1)
        - 참고 1 - [상관계수 구하는 법](http://math7.tistory.com/113) (나부랭이의 수학블로그, 2015)
    - Lecture: 선형 회귀 모델 개요  - [강의자료](https://doc.co/YZmpW9)
        - 참고 1 - [프로그래머를 위한 미분 강의](https://youtu.be/LwhK9HBEVAM) (홍정모, 2016)
    - Lab : 상관분석 - [강의자료](https://doc.co/KAdm49)
    - Lab : 선형회귀 모델 - [강의자료](https://doc.co/pXRgaD)
    - Lecture: 경사하강법 (Gradient Descent) - [강의자료](https://doc.co/NTaRyv)
    - Lecture: 선형회귀를 위한 경사하강법 - [강의자료](https://doc.co/VvY4rk)
    - Lab: 선형회귀 경사하강법 구현 - [강의자료](https://doc.co/GJjb9V)
    - Lecture: Cost Fucntion Graph
    - Lecture: PyData Package: Tensorflow vs Scikit-learn - [강의자료](https://doc.co/qR89fb)
    - Lab: Linear Regression Tensorflow - [강의자료](https://doc.co/x96Edn)
        - 참고 1 :[Linear Regression의 Hypothesis 와 cost 설명](https://youtu.be/Hax03rCn3UI?list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm) (김성훈, 2016)
        - 참고 2 :[Tensorflow로 간단한 Linear Regression을 구현](https://youtu.be/4HrSxpi3IAM?list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm) (김성훈, 2016)
        - 참고 3 :[Linear Regression의 cost 최소화 알고리즘의 원리 설명](https://www.youtube.com/watch?v=TxIVr-nk1so&index=6&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm) (김성훈, 2016)
    - Assignment: Tensorflow로 Linear Regression 구현하기 
    - Lab: Linear Regression Scikit-learn - [강의자료](https://doc.co/WGwUe5)
    - Lecture: 다중 선형회귀 개요  - [강의자료](https://doc.co/Pos9iC/miwc5C)
    - Lecture: 다중 선형회귀 구현(w/Gradient Descent) - [강의자료](https://doc.co/kns8Ty/miwc5C)
    - Lab: 다중 선형 회귀 구현(w/Gradient Descent) - [강의자료](https://doc.co/dXwGbh/miwc5C)
    - Lecture: 데이터 정규화 
    - Lab: 다중 선형회귀 모델 Tenrsorflow & Scikit-learn 구현 
        - 참고 1 :[Multi-variable linear regression](https://www.youtube.com/watch?v=UYWJkyYln2s&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm&index=8) (김성훈, 2016)
        - 참고 2 :[Multi-variable linear regression을 TensorFlow에서 구현하기](https://www.youtube.com/watch?v=iEaVR1N8EEk&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm&index=9) (김성훈, 2016)
* 로지스틱 회귀 (Logistic regression)
    - Lecture: 분류 문제 개요 (Classification Problem Overview) - [강의자료](https://doc.co/R1MpqF/miwc5C)
    - Lecture: 로지스틱 회귀 개요 (Logistic Regression Overview) - [강의자료](https://doc.co/6wWbDs/miwc5C)
    - Lab: 경사하강법으로 로지스틱 회귀 구현 (Pure Python)
    - Lab: Scikit-learn과 Tensorflow로 로지스틱 회귀 구현 
        - 참고 1 :[Logistic Classification의 가설 함수 정의](https://www.youtube.com/watch?v=PIjno6paszY&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm&index=10) (김성훈, 2016)
        - 참고 2 :[Logistic Regression의 cost 함수 설명](https://www.youtube.com/watch?v=6vzchGYEJBc&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm&index=11) (김성훈, 2016)
        - 참고 3 :[TensorFlow로 Logistic Classification의 구현하기](https://www.youtube.com/watch?v=t7Y9luCNzzE&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm&index=12) (김성훈, 2016)
    - Lecture: 범주형 자료와 다항 로지스틱 회귀 (Categorical data and Multinomial Logistic Regression) - [code](code/2_logistic_regression/5_categorical_data_logistic_regression.ipynb)
    - Lab: 범주형 자료와 다항 로지스틱 회귀 구현 (Pure Python)
    - Lab: 범주형 자료와 다항 로지스틱 회귀 구현 II (Tensorflow, Scikit-learn) - [강의자료](https://doc.co/2K3EfX/miwc5C), [Code](./code/2_logistic_regression/6_multinomail_logistic_regression.ipynb)
    - Lecture: 분류 서비스 구현하기 - [강의자료](https://doc.co/QSHysn/miwc5C), [Modelling code](./code/2_logistic_regression/7_classification_service.ipynb),  [Service code](./code/2_logistic_regression/8_logistic_service_server.py)
* 분석 성능 측정과 개선 (Performance Evaluation )
    - Lecture: 분류/회귀 문제의 성능 측정 - [강의자료](https://doc.co/bcmdod/miwc5C)
        - RM 1 : Scratch Ch 11(p143~p147)
        - RM 2 : DDS Ch 3(p92), Ch 5(p140~p153)
    - Lab: 분류 문제의 성능 측정 - [Code](./code/3_analysis_performance/1_measure_classification_performance.ipynb)
    - Lab: 회귀 문제의 성능 측정 - [Code](./code/3_analysis_performance/2_measure_regression_performance.ipynb)
    - Lecture: 어떻게 성능을 개선할 것인가?
        - 참고 1 :[Overfitting](http://sanghyukchun.github.io/59/) (전상혁, 2014)
    - Lecture: 성능 개선 1 - 벌점 회귀 (Penalizaed Regression)
    - Lab: 벌점 회귀 구현 I (Numpy) 
    - Lab: 벌점 회귀 구현 II (Tensorflow & Scikit-Learn) 
    - Lecture: 성능 개선 2 - Feature Engineering
    - Lab: Feature Selection with Pandas
    - Lecture: 성능 개선 3 - 경사하강법 알고리즘의 선택
    - Lab: SGD 알고리즘 구현
* 나이브 베이즈 분류기 (Navie Bayes Classifier)
    - Lecture: 나이브 베이즈 분류기 개요 (Naive Bayesian Classifier Overview)
        - RM 1 : DDS Ch 4(p117)
        - RM 2 : scratch Ch 13
    - Lab: 나이브 베이즈 분류기 구현 (Numpy)
    - Lab: 스팸필터 분류기 (Scikit-Learn)
    - Lab: Text-mining 뉴스 분류기 (Scikit-Learn & NLTK)
* 의사 결정 트리 (Decision Tree )
    - 의사결정트리 모델
* 서포트 벡터 머신(Support Vector Machine)
    - SVM 
* 뉴럴 네트웤(Neural network)
    - Neural network 개념의 이해
    - 미분 - Chain rule
    - Backpropagation
    
### 비지도 학습 (Unupervised learning)
* K-Means clustering
* PCA
* SVM clustering

## 참고자료
* Andrew Ng - Machine Learning (Couera)
* Sung Kim - 모두를 위한 딥러닝



    


