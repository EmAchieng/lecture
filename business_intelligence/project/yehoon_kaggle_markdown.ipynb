{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Kaggle - Two Sigma Connect: Rental Listing Inquiries_Yehoon</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>모듈 호출</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "import random\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Imputer, LabelBinarizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>데이터 호출</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df=pd.read_json('train.json')\n",
    "test_df=pd.read_json('test.json')\n",
    "\n",
    "train_df = train_df.sort_index(axis=1)\n",
    "test_df = test_df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>XGB 호출</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1500):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.02\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Basic Feature 추가</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_use=[\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\",\n",
    "                 \"price_t\",\"photo_count\",  \"num_description_words\",\"listing_id\",\n",
    "                 \"display_address\", \"manager_id\", \"building_id\", \"street_address\",'price_per_room']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Numeric Features - room, bedroom, bathroom, price, description, photo data </h3><br>\n",
    "- room, bed, bathroom, price 등의 개별적 데이터들을 이용해 pricePedSth Data를 생성함<br>\n",
    "- photo와 description 등 non-numerical data를 numerical data로 전환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    fmt = lambda s: s.replace(\"\\u00a0\", \"\").strip().lower()\n",
    "    df[\"photo_count\"] = df[\"photos\"].apply(len)\n",
    "    df[\"price_t\"] =df[\"price\"]/df[\"bedrooms\"]\n",
    "    df[\"pricePerBed\"] = df['price'] / df['bedrooms']\n",
    "    df[\"pricePerBath\"] = df['price'] / df['bathrooms']\n",
    "    df[\"pricePerRoom\"] = df['price'] / (df['bedrooms'] + df['bathrooms'])\n",
    "    df[\"bedPerBath\"] = df['bedrooms'] / df['bathrooms']\n",
    "    df[\"bedBathDiff\"] = df['bedrooms'] - df['bathrooms']\n",
    "    df[\"bedBathSum\"] = df[\"bedrooms\"] + df['bathrooms']\n",
    "    df[\"bedsPerc\"] = df[\"bedrooms\"] / (df['bedrooms'] + df['bathrooms'])\n",
    "    df[\"num_description_words\"] = df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "    df[\"room_sum\"] = df[\"bedrooms\"]+df[\"bathrooms\"] \n",
    "    df['price_per_room'] = df['price']/df['room_sum']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = add_features(train_df)\n",
    "test_df = add_features(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Manager Id Classify Using Interest Level</h3>\n",
    "- Manager Id를 Interest Level을 이용해 'high', 'medium', 'low'로 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index=list(range(train_df.shape[0]))\n",
    "random.shuffle(index)\n",
    "a=[np.nan]*len(train_df)\n",
    "b=[np.nan]*len(train_df)\n",
    "c=[np.nan]*len(train_df)\n",
    "\n",
    "for i in range(5):\n",
    "    building_level={}\n",
    "    for j in train_df['manager_id'].values:\n",
    "        building_level[j]=[0,0,0]\n",
    "    test_index=index[int((i*train_df.shape[0])/5):int(((i+1)*train_df.shape[0])/5)]\n",
    "    train_index=list(set(index).difference(test_index))\n",
    "    for j in train_index:\n",
    "        temp=train_df.iloc[j]\n",
    "        if temp['interest_level']=='low':\n",
    "            building_level[temp['manager_id']][0]+=1\n",
    "        if temp['interest_level']=='medium':\n",
    "            building_level[temp['manager_id']][1]+=1\n",
    "        if temp['interest_level']=='high':\n",
    "            building_level[temp['manager_id']][2]+=1\n",
    "    for j in test_index:\n",
    "        temp=train_df.iloc[j]\n",
    "        if sum(building_level[temp['manager_id']])!=0:\n",
    "            a[j]=building_level[temp['manager_id']][0]*1.0/sum(building_level[temp['manager_id']])\n",
    "            b[j]=building_level[temp['manager_id']][1]*1.0/sum(building_level[temp['manager_id']])\n",
    "            c[j]=building_level[temp['manager_id']][2]*1.0/sum(building_level[temp['manager_id']])\n",
    "train_df['manager_level_low']=a\n",
    "train_df['manager_level_medium']=b\n",
    "train_df['manager_level_high']=c\n",
    "\n",
    "\n",
    "\n",
    "a=[]\n",
    "b=[]\n",
    "c=[]\n",
    "building_level={}\n",
    "for j in train_df['manager_id'].values:\n",
    "    building_level[j]=[0,0,0]\n",
    "for j in range(train_df.shape[0]):\n",
    "    temp=train_df.iloc[j]\n",
    "    if temp['interest_level']=='low':\n",
    "        building_level[temp['manager_id']][0]+=1\n",
    "    if temp['interest_level']=='medium':\n",
    "        building_level[temp['manager_id']][1]+=1\n",
    "    if temp['interest_level']=='high':\n",
    "        building_level[temp['manager_id']][2]+=1\n",
    "\n",
    "for i in test_df['manager_id'].values:\n",
    "    if i not in building_level.keys():\n",
    "        a.append(np.nan)\n",
    "        b.append(np.nan)\n",
    "        c.append(np.nan)\n",
    "    else:\n",
    "        a.append(building_level[i][0]*1.0/sum(building_level[i]))\n",
    "        b.append(building_level[i][1]*1.0/sum(building_level[i]))\n",
    "        c.append(building_level[i][2]*1.0/sum(building_level[i]))\n",
    "test_df['manager_level_low']=a\n",
    "test_df['manager_level_medium']=b\n",
    "test_df['manager_level_high']=c\n",
    "\n",
    "features_to_use.append('manager_level_low') \n",
    "features_to_use.append('manager_level_medium') \n",
    "features_to_use.append('manager_level_high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Select Key-Featuers of Room</h3>\n",
    "- Feature 중 출현 빈도수가 높아 결과에 영향을 끼치는 정도가 큰 Feature들을 TF-IDF 후 추가함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets_1= [\"No Fee\"]\n",
    "train_df[\"No_Fee\"]=train_df.features.apply(lambda sentence: any(word in sentence for word in targets_1))\n",
    "train_df.No_Fee=train_df.No_Fee.astype(int)\n",
    "\n",
    "targets_2= [\"Cat Allowed\"]\n",
    "train_df[\"Cat_Allowed\"]=train_df.features.apply(lambda sentence: any(word in sentence for word in targets_2))\n",
    "train_df.Cat_Allowed=train_df.Cat_Allowed.astype(int)\n",
    "\n",
    "targets_3= [\"Dog Allowed\"]\n",
    "train_df[\"Dog_Allowed\"]=train_df.features.apply(lambda sentence: any(word in sentence for word in targets_3))\n",
    "train_df.Dog_Allowed=train_df.Dog_Allowed.astype(int)\n",
    "\n",
    "targets_4= [\"Elevator\"]\n",
    "train_df[\"Elevator\"]=train_df.features.apply(lambda sentence: any(word in sentence for word in targets_4))\n",
    "train_df.Elevator=train_df.Elevator.astype(int)\n",
    "\n",
    "\n",
    "targets_1= [\"No Fee\"]\n",
    "test_df[\"No_Fee\"]=test_df.features.apply(lambda sentence: any(word in sentence for word in targets_1))\n",
    "test_df.No_Fee=test_df.No_Fee.astype(int)\n",
    "\n",
    "targets_2= [\"Cat Allowed\"]\n",
    "test_df[\"Cat_Allowed\"]=test_df.features.apply(lambda sentence: any(word in sentence for word in targets_2))\n",
    "test_df.Cat_Allowed=test_df.Cat_Allowed.astype(int)\n",
    "\n",
    "targets_3= [\"Dog Allowed\"]\n",
    "test_df[\"Dog_Allowed\"]=test_df.features.apply(lambda sentence: any(word in sentence for word in targets_3))\n",
    "test_df.Dog_Allowed=test_df.Dog_Allowed.astype(int)\n",
    "\n",
    "targets_4= [\"Elevator\"]\n",
    "test_df[\"Elevator\"]=test_df.features.apply(lambda sentence: any(word in sentence for word in targets_4))\n",
    "test_df.Elevator=test_df.Elevator.astype(int)\n",
    "\n",
    "features_to_use.extend([\"No_Fee\", \"Cat_Allowed\", \"Dog_Allowed\", \"Elevator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10                                                         \n",
      "10000     Doorman Elevator Fitness_Center Cats_Allowed D...\n",
      "100004    Laundry_In_Building Dishwasher Hardwood_Floors...\n",
      "100007                               Hardwood_Floors No_Fee\n",
      "100013                                              Pre-War\n",
      "Name: features, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_df['features'] = train_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "test_df['features'] = test_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "print(train_df[\"features\"].head())\n",
    "tfidf = CountVectorizer(stop_words='english', max_features=200)\n",
    "tr_sparse = tfidf.fit_transform(train_df[\"features\"])\n",
    "te_sparse = tfidf.transform(test_df[\"features\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Density and Distance</h3>\n",
    "- longitude와 latitude를 이용하여 중심지로부터의 거리와 건물들 간의 밀집 정도를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.sqrt(((train_df.latitude - train_df.latitude.median())**2) + (train_df.longitude - train_df.longitude.median())**2)\n",
    "train_df['num_dist_from_center'] = x.values\n",
    "x = np.sqrt(((test_df.latitude - train_df.latitude.median())**2) + (test_df.longitude - train_df.longitude.median())**2)\n",
    "test_df['num_dist_from_center'] = x.values\n",
    "features_to_use.extend([\"num_dist_from_center\"])\n",
    "\n",
    "\n",
    "train_df[\"pos\"] = train_df.longitude.round(3).astype(str) + '_' + train_df.latitude.round(3).astype(str)\n",
    "test_df[\"pos\"] = test_df.longitude.round(3).astype(str) + '_' + test_df.latitude.round(3).astype(str)\n",
    "\n",
    "\n",
    "vals = train_df['pos'].value_counts()\n",
    "dvals = vals.to_dict()\n",
    "train_df[\"density\"] = train_df['pos'].apply(lambda x: dvals.get(x, vals.min()))\n",
    "test_df[\"density\"] = test_df['pos'].apply(lambda x: dvals.get(x, vals.min()))\n",
    "features_to_use.extend([\"density\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>5. Categorize with Dispaly Address, Manager Id, Building Id and Street Address</h3>\n",
    "- display address, manager id, building_id, street address를 categorize함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "for f in categorical:\n",
    "        if train_df[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n",
    "            train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "            test_df[f] = lbl.transform(list(test_df[f].values))\n",
    "            features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Set, Test Set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 227) (74659, 227)\n"
     ]
    }
   ],
   "source": [
    "train_X = sparse.hstack([train_df[features_to_use], tr_sparse]).tocsr()\n",
    "test_X = sparse.hstack([test_df[features_to_use], te_sparse]).tocsr()\n",
    "\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "print(train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Logloss and Score</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Logloss : 0.522379 <br>\n",
    "Score : 0.53337</h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
